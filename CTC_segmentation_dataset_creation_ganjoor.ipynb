{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Python cell to clone the repository\n",
    "!git clone https://github.com/saeedzou/NeMo.git\n",
    "%cd NeMo\n",
    "\n",
    "import os\n",
    "\n",
    "NEMO_DIR_PATH = \"./\"\n",
    "TOOLS_DIR = f'{NEMO_DIR_PATH}/tools/ctc_segmentation/scripts'\n",
    "WORK_DIR = 'WORK_DIR'\n",
    "DATA_DIR = WORK_DIR + '/DATA'\n",
    "OUTPUT_DIR = WORK_DIR + \"/output\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR + '/audio', exist_ok=True)\n",
    "os.makedirs(DATA_DIR + '/text', exist_ok=True)\n",
    "\n",
    "! bash colab_install.sh\n",
    "! apt-get install -y sox libsox-fmt-mp3 ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare your data in the following format:\n",
    "- Audios must be under {DATA_DIR}/audio\n",
    "- Texts must be under {DATA_DIR}/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "NVIDIA_FASTCONFORMER = \"nvidia/stt_fa_fastconformer_hybrid_large\"\n",
    "WAV2VEC2_FA = \"masoudmzb/wav2vec2-xlsr-multilingual-53-fa\"\n",
    "WAV2VEC2_V3 = \"m3hrdadfi/wav2vec2-large-xlsr-persian-v3\"\n",
    "WHISPER_TINY = \"openai/whisper-tiny\"\n",
    "WHISPER_BASE = \"openai/whisper-base\"\n",
    "WHISPER_SMALL = \"openai/whisper-small\"\n",
    "WHISPER_MEDIUM = \"openai/whisper-medium\"\n",
    "WHISPER_LARGE = \"openai/whisper-large\"\n",
    "HEZAR = 'hezarai/whisper-small-fa'\n",
    "VOSK_SMALL = 'vosk-model-small-fa-0.42'\n",
    "VOSK_BIG = 'vosk-model-fa-0.42'\n",
    "MODELS = f\"{NVIDIA_FASTCONFORMER} {WAV2VEC2_FA} {HEZAR}\"\n",
    "\n",
    "DATASET_DIR = \"\" # Name of the output dataset folder\n",
    "ZIP_PATH = f\"/content/NeMo/{DATASET_DIR}.zip\"\n",
    "MODE = \"ganjoor\"\n",
    "\n",
    "GDRIVE_ID = \"\" # id of the zip file\n",
    "! gdown $GDRIVE_ID -O $DATA_DIR/audio.zip\n",
    "! unzip -q $DATA_DIR/audio.zip -d $DATA_DIR\n",
    "\n",
    "LANG_ID='fa'\n",
    "OFFSET = 0\n",
    "THRESHOLD = -2\n",
    "WINDOW = 8000\n",
    "CER_THRESHOLD = 40\n",
    "WER_THRESHOLD = 75\n",
    "CER_EDGE_THRESHOLD = 75\n",
    "LEN_DIFF_RATIO_THRESHOLD = 0.4\n",
    "MIN_DURATION = 1\n",
    "MAX_DURATION = 20\n",
    "EDGE_LEN = 7\n",
    "OUTPUT_FORMAT = 'mp3'\n",
    "REMOVE_BRACKETS=False\n",
    "REMOVE_ASTERISKS=False\n",
    "REMOVE_PARENTHESES=False\n",
    "REMOVE_SPEAKER_LABELS=False\n",
    "SPLIT_USING_PATTERN=True\n",
    "SPLIT_ON_QUOTES=False\n",
    "SPLIT_ON_VERBS=True\n",
    "SPLIT_ON_VERBS_MIN_WORDS=5\n",
    "SPLIT_ON_VERBS_MAX_WORDS=20\n",
    "ADDITIONAL_SPLIT_SYMBOLS=\"\" # add new symbols, separated by |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tqdm\n",
    "\n",
    "def get_text_api(id):\n",
    "    url = f'https://api.ganjoor.net/api/audio/verses/{id}'\n",
    "    response = requests.get(url)\n",
    "    # Check if the response status is OK (200)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # If the request failed, return a failure message\n",
    "        return f\"Error: Unable to fetch poem. Status code: {response.status_code}\"\n",
    "\n",
    "# remove texts because it doesn't contain punctuation\n",
    "! rm -rf $DATA_DIR/text\n",
    "os.makedirs(DATA_DIR + '/text', exist_ok=True)\n",
    "ids = [int(f.split('.')[0]) for f in os.listdir(f'{DATA_DIR}/audio') if f.endswith('.mp3')]\n",
    "for id in tqdm(ids):\n",
    "    text = get_text_api(id)\n",
    "    text = \"\\n\".join([x['verseText'] for x in text[1:]])\n",
    "    with open(f'{DATA_DIR}/text/{id}.txt', 'w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script does the following:\n",
    "1. Prepares data in the right format for CTC segmentation i.e. newline separated text (roughly an utterance) and 16000 Hz mono audio in `.wav` format for the NeMo ASR model\n",
    "\n",
    "2. Runs CTC segmentation on the processed data and outputs segments text file for each audio file containing utterance start, end timings and alignment score\n",
    "\n",
    "3. Verifies the segments created in step 2\n",
    "\n",
    "4. Cuts the audios into utterances and creates a json manifest file (NeMo format) of the information of each utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf $OUTPUT_DIR\n",
    "\n",
    "! bash $TOOLS_DIR/../run_segmentation.sh \\\n",
    "--MODEL_NAME_OR_PATH=$NVIDIA_FASTCONFORMER \\\n",
    "--DATA_DIR=$DATA_DIR \\\n",
    "--OUTPUT_DIR=$OUTPUT_DIR \\\n",
    "--SCRIPTS_DIR=$TOOLS_DIR \\\n",
    "--REMOVE_BRACKETS=$REMOVE_BRACKETS \\\n",
    "--REMOVE_ASTERISKS=$REMOVE_ASTERISKS \\\n",
    "--REMOVE_PARANTHESES=$REMOVE_PARENTHESES \\\n",
    "--REMOVE_SPEAKER_LABELS=$REMOVE_SPEAKER_LABELS \\\n",
    "--SPLIT_USING_PATTERN=$SPLIT_USING_PATTERN \\\n",
    "--SPLIT_ON_QUOTES=$SPLIT_ON_QUOTES \\\n",
    "--SPLIT_ON_VERBS=$SPLIT_ON_VERBS \\\n",
    "--ADDITIONAL_SPLIT_SYMBOLS=$ADDITIONAL_SPLIT_SYMBOLS \\\n",
    "--LANGUAGE=$LANG_ID \\\n",
    "--MIN_SCORE=$THRESHOLD  \\\n",
    "--USE_NEMO_NORMALIZATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Transcribes the segments created from the `run_segmentation.sh` using the generated manifest for models in `MODELS` and calculate metrics such as WER, CER, etc. and outputs a new manifest file for each model\n",
    "\n",
    "2. Filters out segments that don't meet the minimum requirements of any of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash $TOOLS_DIR/../run_filter_multiple.sh \\\n",
    "--MODEL_NAME_OR_PATH=\"$MODELS\" \\\n",
    "--INPUT_AUDIO_DIR=$DATA_DIR/audio \\\n",
    "--MANIFEST=$OUTPUT_DIR/manifests/manifest.json \\\n",
    "--SCRIPTS_DIR=$TOOLS_DIR \\\n",
    "--CER_THRESHOLD=$CER_THRESHOLD \\\n",
    "--WER_THRESHOLD=$WER_THRESHOLD \\\n",
    "--CER_EDGE_THRESHOLD=$CER_EDGE_THRESHOLD \\\n",
    "--LEN_DIFF_RATIO_THRESHOLD=$LEN_DIFF_RATIO_THRESHOLD \\\n",
    "--MIN_DURATION=$MIN_DURATION \\\n",
    "--MAX_DURATION=$MAX_DURATION \\\n",
    "--EDGE_LEN=$EDGE_LEN || exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the JSON file\n",
    "MANIFEST_FILE = f'{OUTPUT_DIR}/manifests/manifest_transcribed_metrics_filtered.json'\n",
    "\n",
    "# Count the number of lines in the file\n",
    "with open(MANIFEST_FILE, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "num_lines = len(lines)  # Get the number of lines\n",
    "\n",
    "# Process the file line by line\n",
    "for i, line in enumerate(lines):\n",
    "    if i % (num_lines // 10) == 0:  # Print every 10% of the data\n",
    "        x = json.loads(line.strip())\n",
    "        display(Audio(x['audio_filepath']))\n",
    "        print('Ground Truth: ')\n",
    "        print(x['text'])\n",
    "        print(f'Best hypothesis from {x[\"model_name\"]}')\n",
    "        print(x['pred_text'])\n",
    "        print(f\"WER : {x['WER']}, CER: {x['CER']}, Start CER: {x['start_CER']}, End CER: {x['end_CER']}, Alignment score: {x['score']}\")\n",
    "        print('*' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the results were satisfactory, run the following script to upsample the clips to 44.1 kHz and create a metadata.csv file for the dataset, then zip the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash $TOOLS_DIR/../run_prepare_dataset.sh \\\n",
    "--INPUT_AUDIO_DIR=$DATA_DIR/audio \\\n",
    "--MANIFEST=$OUTPUT_DIR/manifests/manifest_transcribed_metrics_filtered.json \\\n",
    "--SCRIPTS_DIR=$TOOLS_DIR \\\n",
    "--OUTPUT_DIR=$OUTPUT_DIR \\\n",
    "--OUTPUT_FORMAT=$OUTPUT_FORMAT \\\n",
    "--MODE=$MODE \\\n",
    "--DATASET_DIR=$DATASET_DIR || exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "! mkdir -p /content/drive/MyDrive/Ganjoor_Dataset\n",
    "! cp $ZIP_PATH /content/drive/MyDrive/Ganjoor_Dataset\n",
    "print(f\"Dataset is saved in /content/drive/MyDrive/Ganjoor_Dataset/{DATASET_DIR}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
